{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from models.DiffLoad.diffusion.layers import CondModel_v2\n",
    "from matplotlib import pyplot as plt\n",
    "from utils.helper import make_beta_schedule, EMA, ObjectView\n",
    "from utils.plots import hdr_plot_style\n",
    "hdr_plot_style()\n",
    "from tqdm import tqdm\n",
    "from models.DiffLoad.ddpm import DDPM1d\n",
    "from utils.config import config_dataset, config_ddpm, config_nn"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "configs = {\n",
    "    'epoch': 80000,\n",
    "    'batch_size': 3000,\n",
    "    'learning_rate': 1e-4,\n",
    "    'lr_decay': 0.99,\n",
    "    'lr_decay_step': 200,\n",
    "    'mode': None, # [\"checkpoint\", None]\n",
    "    'use_MLP':True,\n",
    "    'use_solar':False\n",
    "}\n",
    "configs.update(config_dataset)\n",
    "configs.update(config_ddpm)\n",
    "configs.update(config_nn)\n",
    "args = ObjectView(configs)\n",
    "args.save_name = \"diff_phy\" if args.use_solar else \"diff_base\"\n",
    "print(args.save_name)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "num_user = 50"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "X_train = torch.load(\"../data/Pecan Street Smart Meter Data (large) (tensor)/X_train.pt\")\n",
    "X_test = torch.load(\"../data/Pecan Street Smart Meter Data (large) (tensor)/X_test.pt\")\n",
    "cond_train = torch.load(\"../data/Pecan Street Smart Meter Data (large) (tensor)/cond_train.pt\")\n",
    "cond_test = torch.load(\"../data/Pecan Street Smart Meter Data (large) (tensor)/cond_test.pt\")\n",
    "PV_base_train = torch.load(\"../data/Pecan Street Smart Meter Data (large) (tensor)/PV_base_train.pt\")\n",
    "PV_base_test = torch.load(\"../data/Pecan Street Smart Meter Data (large) (tensor)/PV_base_test.pt\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(X_train.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Select betas\n",
    "n_steps = args.n_steps\n",
    "\n",
    "betas = make_beta_schedule(schedule='linear', n_timesteps=n_steps, start=args.beta_start, end=args.beta_end)\n",
    "betas = betas.to(device)\n",
    "model = CondModel_v2(args)\n",
    "if args.mode == \"checkpoint\":\n",
    "    checkpoint = torch.load('../result/models/pecan/{}.pth'.format(args.save_name))\n",
    "    model = checkpoint['ddpm'].model\n",
    "    args.learning_rate = args.learning_rate * args.lr_decay ** (args.epoch/args.lr_decay_step)\n",
    "\n",
    "print(args.learning_rate)\n",
    "model = model.to(device)\n",
    "X_train = X_train.to(device)\n",
    "cond_train = cond_train.to(device)\n",
    "PV_base_train = PV_base_train.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=args.lr_decay_step, gamma=args.lr_decay)\n",
    "ddpm = DDPM1d(model, betas, n_steps, (args.input_dim,), loss_type='l2')\n",
    "# Create EMA model\n",
    "ema = EMA(args.ema_decay)\n",
    "ema.register(model)\n",
    "\n",
    "Loss = []\n",
    "for j in tqdm(range(args.epoch)):\n",
    "    # X is a torch Variable\n",
    "    loss_a = 0\n",
    "    permutation = torch.randperm(X_train.size()[0])\n",
    "    for i in range(0, X_train.size()[0], args.batch_size):\n",
    "        # Retrieve current batch \n",
    "        indices = permutation[i:i+args.batch_size]\n",
    "        batch_x = X_train[indices]\n",
    "        batch_x = batch_x + 0.05 * torch.randn_like(batch_x)\n",
    "        batch_cond = cond_train[indices]\n",
    "        # Compute the loss.\n",
    "        if args.use_solar == True:\n",
    "            batch_PV_base = PV_base_train[indices]\n",
    "            loss = ddpm(batch_x, batch_cond, batch_PV_base)\n",
    "        else:\n",
    "            loss = ddpm(batch_x, batch_cond)\n",
    "        # Before the backward pass, zero all of the network gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Backward pass: compute gradient of the loss with respect to parameters\n",
    "        loss.backward()\n",
    "        # \n",
    "        loss_a = loss_a + loss.item()\n",
    "        # Perform gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.)\n",
    "        # Calling the step function to update the parameters\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        # Update the exponential moving average\n",
    "        ema.update(model)\n",
    "        ddpm.model = model\n",
    "    \n",
    "    loss_a = loss_a / X_train.size()[0] * args.batch_size\n",
    "    if (j+1) % 100 == 0:\n",
    "        Loss.append(loss_a)\n",
    "    if (j+1) % 10000 == 0:\n",
    "        print(\"loss: \", loss_a)\n",
    "    if (j+1) % 10000 == 0 or (j+1) == args.epoch:\n",
    "        checkpoint = {\n",
    "            'config': configs,\n",
    "            'ddpm': ddpm,\n",
    "            'Loss': Loss\n",
    "        }\n",
    "        torch.save(checkpoint, \"../result/models/pecan/{}.pth\".format(args.save_name))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.plot(Loss)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cond_test = cond_test.to(device)\n",
    "PV_base_test = PV_base_test.to(device)\n",
    "X_test_hat = ddpm.sample_seq(batch_size=len(cond_test), cond=cond_test)[-1]\n",
    "X_test_hat = X_test_hat.to(\"cpu\")\n",
    "X_test_hat = X_test_hat.reshape(args.num_class, -1, 96)\n",
    "X_test = X_test.reshape(args.num_class, -1, 96)\n",
    "for j in range(config_dataset[\"num_class\"])[:10]:\n",
    "    plt.figure(figsize=(36,6), dpi=300)\n",
    "    plt.subplot(1,4,1)\n",
    "    for i in range(len(X_test[j])):\n",
    "        plt.plot(X_test[j][i])\n",
    "    plt.title(\"actual data\")\n",
    "    plt.subplot(1,4,2)\n",
    "    for i in range(len(X_test_hat[j])):\n",
    "        plt.plot(X_test_hat[j][i])\n",
    "    plt.title(\"generated load profile (MLP0_Solar0)\")\n",
    "\n",
    "    plt.subplot(1,4,3)\n",
    "    plt.plot(X_test_hat[j].mean(dim=0), label = \"mean of generated data\")\n",
    "    plt.plot(X_test[j].mean(dim=0), label = \"mean of actual data\")\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.subplot(1,4,4)\n",
    "    plt.plot(X_test_hat[j].var(dim=0), label = \"var of generated data\")\n",
    "    plt.plot(X_test[j].var(dim=0), label = \"var of actual data\")\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.tight_layout()\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
